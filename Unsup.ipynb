{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d280de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scapy.all import PcapReader, IP, TCP, UDP, ICMP, DNS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (silhouette_score, silhouette_samples, davies_bouldin_score, calinski_harabasz_score)\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f747cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BiLSTMSequenceFeatureExtractor:\n",
    "    \"\"\"Extract BiLSTM sequence features from PCAP files\"\"\"\n",
    "    \n",
    "    def __init__(self, sequence_length=50):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def extract_sequence_features(self, packet):\n",
    "        \"\"\"Extract 13 features from a single packet (same as BiLSTM)\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        try:\n",
    "            if IP in packet:\n",
    "                # Packet length (normalized to 1500 max)\n",
    "                features.append(min(len(packet) / 1500.0, 1.0))\n",
    "                \n",
    "                # IP TTL (normalized to 255 max)\n",
    "                features.append(packet[IP].ttl / 255.0)\n",
    "                \n",
    "                # IP flags\n",
    "                features.append(int(packet[IP].flags) / 7.0)\n",
    "                \n",
    "                # IP ID variation\n",
    "                features.append((packet[IP].id % 1000) / 1000.0)\n",
    "                \n",
    "                if TCP in packet:\n",
    "                    # TCP ports\n",
    "                    features.append(packet[TCP].sport / 65535.0)\n",
    "                    features.append(packet[TCP].dport / 65535.0)\n",
    "                    \n",
    "                    # TCP flags\n",
    "                    features.append(int(packet[TCP].flags) / 63.0)\n",
    "                    \n",
    "                    # TCP window size\n",
    "                    features.append(packet[TCP].window / 65535.0)\n",
    "                    \n",
    "                    # Payload length\n",
    "                    payload_len = len(packet[TCP].payload)\n",
    "                    features.append(min(payload_len / 1500.0, 1.0))\n",
    "                    \n",
    "                    # TCP options count\n",
    "                    features.append(min(float(len(packet[TCP].options)) / 10.0, 1.0))\n",
    "                    \n",
    "                    # Payload entropy\n",
    "                    features.append(self._payload_entropy(bytes(packet[TCP].payload)))\n",
    "                    \n",
    "                    features.extend([0.0, 0.0])\n",
    "                    \n",
    "                elif UDP in packet:\n",
    "                    features.append(packet[UDP].sport / 65535.0)\n",
    "                    features.append(packet[UDP].dport / 65535.0)\n",
    "                    \n",
    "                    payload_len = len(packet[UDP].payload)\n",
    "                    features.append(min(payload_len / 1500.0, 1.0))\n",
    "                    \n",
    "                    features.extend([0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "                    \n",
    "                else:\n",
    "                    features.extend([0.0] * 10)\n",
    "                \n",
    "                # ICMP\n",
    "                features.append(1.0 if ICMP in packet else 0.0)\n",
    "                \n",
    "                # DNS\n",
    "                features.append(1.0 if DNS in packet else 0.0)\n",
    "            else:\n",
    "                features = [0.0] * 13\n",
    "        \n",
    "        except:\n",
    "            features = [0.0] * 13\n",
    "        \n",
    "        return np.array(features[:13])\n",
    "    \n",
    "    def _payload_entropy(self, payload):\n",
    "        \"\"\"Calculate normalized Shannon entropy\"\"\"\n",
    "        if not payload or len(payload) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        byte_counts = np.bincount(list(payload), minlength=256)\n",
    "        probabilities = byte_counts[byte_counts > 0] / len(payload)\n",
    "        ent = entropy(probabilities, base=2) / 8.0\n",
    "        return min(ent, 1.0)\n",
    "    \n",
    "    def extract_flows_from_pcap(self, pcap_file, label, max_flows=1000):\n",
    "        \"\"\"Extract packet flows from PCAP file\"\"\"\n",
    "        print(f\"\\nProcessing {pcap_file} (Label: {'Steganography' if label == 1 else 'Benign'})...\")\n",
    "        \n",
    "        flow_dict = defaultdict(list)\n",
    "        \n",
    "        try:\n",
    "            with PcapReader(pcap_file) as pcap:\n",
    "                for packet in tqdm(pcap, desc=\"   Reading packets\"):\n",
    "                    if IP not in packet:\n",
    "                        continue\n",
    "                    \n",
    "                    # Flow identifier\n",
    "                    src_ip = packet[IP].src\n",
    "                    dst_ip = packet[IP].dst\n",
    "                    proto = packet[IP].proto\n",
    "                    \n",
    "                    if TCP in packet:\n",
    "                        src_port = packet[TCP].sport\n",
    "                        dst_port = packet[TCP].dport\n",
    "                    elif UDP in packet:\n",
    "                        src_port = packet[UDP].sport\n",
    "                        dst_port = packet[UDP].dport\n",
    "                    else:\n",
    "                        src_port = 0\n",
    "                        dst_port = 0\n",
    "                    \n",
    "                    # Create flow key (bidirectional)\n",
    "                    flow_key = tuple(sorted([\n",
    "                        (src_ip, src_port, proto),\n",
    "                        (dst_ip, dst_port, proto)\n",
    "                    ]))\n",
    "                    \n",
    "                    # Extract features\n",
    "                    features = self.extract_sequence_features(packet)\n",
    "                    flow_dict[flow_key].append(features)\n",
    "            \n",
    "            print(f\"   ✓ Extracted {len(flow_dict)} flows\")\n",
    "            return flow_dict, label\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "            return {}, label\n",
    "    \n",
    "    def aggregate_flow_features(self, flow_dict):\n",
    "        \"\"\"Aggregate sequence features into single flow feature vector\"\"\"\n",
    "        sequences_data = []\n",
    "        \n",
    "        for flow_key, packets in tqdm(flow_dict.items(), desc=\"   Aggregating features\"):\n",
    "            if len(packets) >= 3:  # Minimum 3 packets\n",
    "                # Pad or truncate to sequence_length\n",
    "                if len(packets) < self.sequence_length:\n",
    "                    packets = packets + [np.zeros(13)] * (self.sequence_length - len(packets))\n",
    "                else:\n",
    "                    packets = packets[:self.sequence_length]\n",
    "                \n",
    "                packets_array = np.array(packets)\n",
    "                \n",
    "                # Calculate aggregated statistics for each feature dimension\n",
    "                agg_features = []\n",
    "                \n",
    "                for feat_idx in range(13):\n",
    "                    feat_values = packets_array[:, feat_idx]\n",
    "                    \n",
    "                    # Statistical features: mean, std, min, max, median\n",
    "                    agg_features.append(np.mean(feat_values))\n",
    "                    agg_features.append(np.std(feat_values))\n",
    "                    agg_features.append(np.min(feat_values))\n",
    "                    agg_features.append(np.max(feat_values))\n",
    "                    agg_features.append(np.median(feat_values))\n",
    "                \n",
    "                sequences_data.append(np.array(agg_features))\n",
    "        \n",
    "        return np.array(sequences_data)  # Shape: (n_flows, 13*5=65 features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38b9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedClusteringAnalysis:\n",
    "    \"\"\"Unsupervised clustering using BiLSTM features\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.y_true = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.clusters = None\n",
    "        self.kmeans = None\n",
    "        self.pca = None\n",
    "        self.tsne = None\n",
    "        \n",
    "    def load_features_from_pcaps(self, benign_pcap, stego_pcap,max_flows_per_class=500, sequence_length=50):\n",
    "        \n",
    "        extractor = BiLSTMSequenceFeatureExtractor(sequence_length=sequence_length)\n",
    "        \n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Process benign PCAP\n",
    "        benign_flows, benign_label = extractor.extract_flows_from_pcap(benign_pcap, label=0, max_flows=max_flows_per_class)\n",
    "        \n",
    "        if benign_flows:\n",
    "            print(f\"   Aggregating benign flow features...\")\n",
    "            benign_features = extractor.aggregate_flow_features(benign_flows)\n",
    "            all_features.append(benign_features)\n",
    "            all_labels.extend([benign_label] * len(benign_features))\n",
    "        \n",
    "        # Process stego PCAP\n",
    "        stego_flows, stego_label = extractor.extract_flows_from_pcap(\n",
    "            stego_pcap, label=1, max_flows=max_flows_per_class\n",
    "        )\n",
    "        \n",
    "        if stego_flows:\n",
    "            print(f\"   Aggregating stego flow features...\")\n",
    "            stego_features = extractor.aggregate_flow_features(stego_flows)\n",
    "            all_features.append(stego_features)\n",
    "            all_labels.extend([stego_label] * len(stego_features))\n",
    "        \n",
    "        # Combine datasets\n",
    "        self.X = np.vstack(all_features)\n",
    "        self.y_true = np.array(all_labels)\n",
    "        \n",
    "        print(f\"\\nCombined dataset shape: {self.X.shape}\")\n",
    "        print(f\"  - Samples: {len(self.X):,}\")\n",
    "        print(f\"  - Features: {self.X.shape[1]} (13 dims × 5 stats)\")\n",
    "        \n",
    "        # Class distribution\n",
    "        print(f\"\\nClass Distribution:\")\n",
    "        unique, counts = np.unique(self.y_true, return_counts=True)\n",
    "        for label, count in zip(unique, counts):\n",
    "            label_name = \"Steganography\" if label == 1 else \"Benign\"\n",
    "            percentage = (count / len(self.y_true)) * 100\n",
    "            print(f\"   {label_name:<20} {count:>6,} ({percentage:>5.1f}%)\")\n",
    "        \n",
    "        # Normalize\n",
    "        print(f\"\\nNormalizing features...\")\n",
    "        self.X = self.scaler.fit_transform(self.X)\n",
    "        print(f\"Features normalized\")\n",
    "    \n",
    "    def determine_optimal_k(self, k_range=range(2, 11)):\n",
    "        \n",
    "        inertias = []\n",
    "        silhouette_scores = []\n",
    "        davies_bouldin_scores = []\n",
    "        calinski_harabasz_scores = []\n",
    "        \n",
    "        print(f\"\\nTesting K values from {k_range.start} to {k_range.stop-1}...\")\n",
    "        \n",
    "        for k in tqdm(k_range, desc=\"   Evaluating\"):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            labels = kmeans.fit_predict(self.X)\n",
    "            \n",
    "            inertias.append(kmeans.inertia_)\n",
    "            silhouette_scores.append(silhouette_score(self.X, labels))\n",
    "            davies_bouldin_scores.append(davies_bouldin_score(self.X, labels))\n",
    "            calinski_harabasz_scores.append(calinski_harabasz_score(self.X, labels))\n",
    "        \n",
    "        optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  - Optimal K (Silhouette): {optimal_k}\")\n",
    "        print(f\"  - Best Silhouette Score: {max(silhouette_scores):.4f}\")\n",
    "        \n",
    "        self._plot_elbow_analysis(k_range, inertias, silhouette_scores, davies_bouldin_scores, calinski_harabasz_scores, optimal_k)\n",
    "        \n",
    "        return optimal_k\n",
    "    \n",
    "    def _plot_elbow_analysis(self, k_range, inertias, silhouette_scores, davies_bouldin_scores, calinski_harabasz_scores, optimal_k):\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        k_values = list(k_range)\n",
    "        \n",
    "        # Inertia\n",
    "        axes[0, 0].plot(k_values, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "        axes[0, 0].axvline(optimal_k, color='red', linestyle='--', linewidth=2, label=f'Optimal K={optimal_k}')\n",
    "        axes[0, 0].set_xlabel('K', fontsize=11, fontweight='bold')\n",
    "        axes[0, 0].set_ylabel('Inertia', fontsize=11, fontweight='bold')\n",
    "        axes[0, 0].set_title('Elbow Method', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].legend()\n",
    "        \n",
    "        # Silhouette\n",
    "        axes[0, 1].plot(k_values, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
    "        axes[0, 1].axvline(optimal_k, color='red', linestyle='--', linewidth=2, label=f'Optimal K={optimal_k}')\n",
    "        axes[0, 1].set_xlabel('K', fontsize=11, fontweight='bold')\n",
    "        axes[0, 1].set_ylabel('Silhouette Score', fontsize=11, fontweight='bold')\n",
    "        axes[0, 1].set_title('Silhouette Analysis', fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].legend()\n",
    "        \n",
    "        # Davies-Bouldin\n",
    "        axes[1, 0].plot(k_values, davies_bouldin_scores, 'mo-', linewidth=2, markersize=8)\n",
    "        axes[1, 0].axvline(optimal_k, color='red', linestyle='--', linewidth=2, label=f'Optimal K={optimal_k}')\n",
    "        axes[1, 0].set_xlabel('K', fontsize=11, fontweight='bold')\n",
    "        axes[1, 0].set_ylabel('Davies-Bouldin Index', fontsize=11, fontweight='bold')\n",
    "        axes[1, 0].set_title('Davies-Bouldin (lower is better)', fontsize=12, fontweight='bold')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        axes[1, 0].legend()\n",
    "        \n",
    "        # Calinski-Harabasz\n",
    "        axes[1, 1].plot(k_values, calinski_harabasz_scores, 'co-', linewidth=2, markersize=8)\n",
    "        axes[1, 1].axvline(optimal_k, color='red', linestyle='--', linewidth=2, label=f'Optimal K={optimal_k}')\n",
    "        axes[1, 1].set_xlabel('K', fontsize=11, fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('Calinski-Harabasz Index', fontsize=11, fontweight='bold')\n",
    "        axes[1, 1].set_title('Calinski-Harabasz (higher is better)', fontsize=12, fontweight='bold')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "        \n",
    "        plt.savefig('results/01_elbow_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\n Saved: results/01_elbow_analysis.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def perform_clustering(self, optimal_k):\n",
    "        \n",
    "        print(f\"\\nClustering with K={optimal_k}...\")\n",
    "        self.kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "        self.clusters = self.kmeans.fit_predict(self.X)\n",
    "        \n",
    "        print(f\"Clustering completed\")\n",
    "        \n",
    "        # Cluster statistics\n",
    "        print(f\"\\nCluster Distribution:\")\n",
    "        unique, counts = np.unique(self.clusters, return_counts=True)\n",
    "        for cluster_id, count in zip(unique, counts):\n",
    "            percentage = (count / len(self.clusters)) * 100\n",
    "            print(f\"   Cluster {cluster_id}: {count:>6,} ({percentage:>5.1f}%)\")\n",
    "        \n",
    "        # Cluster purity\n",
    "        print(f\"\\nCluster Purity Analysis:\")\n",
    "        for cluster_id in np.unique(self.clusters):\n",
    "            mask = self.clusters == cluster_id\n",
    "            cluster_labels = self.y_true[mask]\n",
    "            \n",
    "            if len(cluster_labels) > 0:\n",
    "                stego_count = np.sum(cluster_labels == 1)\n",
    "                benign_count = np.sum(cluster_labels == 0)\n",
    "                stego_pct = (stego_count / len(cluster_labels)) * 100\n",
    "                \n",
    "                purity = \"PURE STEGO\" if stego_pct > 90 else (\"PURE BENIGN\" if stego_pct < 10 else \"MIXED\")\n",
    "                print(f\"   Cluster {cluster_id}: {stego_pct:>5.1f}% Stego, {100-stego_pct:>5.1f}% Benign [{purity}]\")\n",
    "    \n",
    "    def reduce_dimensions_pca(self):\n",
    "        \n",
    "        print(f\"\\nApplying PCA...\")\n",
    "        self.pca = PCA(n_components=2, random_state=42)\n",
    "        X_pca = self.pca.fit_transform(self.X)\n",
    "        \n",
    "        explained = self.pca.explained_variance_ratio_.sum() * 100\n",
    "        print(f\"✓ Explained variance: {explained:.2f}%\")\n",
    "        print(f\"  - PC1: {self.pca.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "        print(f\"  - PC2: {self.pca.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "        \n",
    "        return X_pca\n",
    "    \n",
    "    def reduce_dimensions_tsne(self):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" t-SNE DIMENSIONALITY REDUCTION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"\\nApplying t-SNE (may take a moment)...\")\n",
    "        self.tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000, verbose=1)\n",
    "        X_tsne = self.tsne.fit_transform(self.X)\n",
    "        \n",
    "        print(f\"t-SNE completed\")\n",
    "        return X_tsne\n",
    "    \n",
    "    def plot_visualizations(self, X_pca, X_tsne, optimal_k):\n",
    "        \"\"\"Plot all visualizations\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" GENERATING VISUALIZATIONS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "        \n",
    "        # PCA visualization\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=self.clusters, cmap='tab10',alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "        axes[0].set_xlabel('PC1', fontsize=11, fontweight='bold')\n",
    "        axes[0].set_ylabel('PC2', fontsize=11, fontweight='bold')\n",
    "        axes[0].set_title(f'PCA - Colored by Clusters (K={optimal_k})', fontsize=12, fontweight='bold')\n",
    "        axes[0].grid(True, alpha=0.2)\n",
    "        \n",
    "        colors = ['#2ecc71' if label == 0 else '#e74c3c' for label in self.y_true]\n",
    "        axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=colors, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "        axes[1].set_xlabel('PC1', fontsize=11, fontweight='bold')\n",
    "        axes[1].set_ylabel('PC2', fontsize=11, fontweight='bold')\n",
    "        axes[1].set_title('PCA - Colored by True Labels', fontsize=12, fontweight='bold')\n",
    "        axes[1].grid(True, alpha=0.2)\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        legend = [Patch(facecolor='#2ecc71', label='Benign'), \n",
    "                 Patch(facecolor='#e74c3c', label='Stego')]\n",
    "        axes[1].legend(handles=legend)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/02_pca_clusters.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\n✓ Saved: results/02_pca_clusters.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # t-SNE visualization\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        axes[0].scatter(X_tsne[:, 0], X_tsne[:, 1], c=self.clusters, cmap='tab10',alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "        axes[0].set_xlabel('t-SNE 1', fontsize=11, fontweight='bold')\n",
    "        axes[0].set_ylabel('t-SNE 2', fontsize=11, fontweight='bold')\n",
    "        axes[0].set_title(f't-SNE - Colored by Clusters (K={optimal_k})', fontsize=12, fontweight='bold')\n",
    "        axes[0].grid(True, alpha=0.2)\n",
    "        \n",
    "        axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "        axes[1].set_xlabel('t-SNE 1', fontsize=11, fontweight='bold')\n",
    "        axes[1].set_ylabel('t-SNE 2', fontsize=11, fontweight='bold')\n",
    "        axes[1].set_title('t-SNE - Colored by True Labels', fontsize=12, fontweight='bold')\n",
    "        axes[1].grid(True, alpha=0.2)\n",
    "        axes[1].legend(handles=legend)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/02_tsne_clusters.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\" Saved: results/02_tsne_clusters.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Silhouette analysis\n",
    "        silhouette_vals = silhouette_samples(self.X, self.clusters)\n",
    "        silhouette_avg = silhouette_score(self.X, self.clusters)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        y_lower = 10\n",
    "        colors_sil = plt.cm.tab10(np.linspace(0, 1, optimal_k))\n",
    "        \n",
    "        for i in range(optimal_k):\n",
    "            cluster_silhouette_vals = silhouette_vals[self.clusters == i]\n",
    "            cluster_silhouette_vals.sort()\n",
    "            \n",
    "            size_cluster_i = cluster_silhouette_vals.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "            \n",
    "            ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_vals,\n",
    "                            facecolor=colors_sil[i], edgecolor=colors_sil[i], alpha=0.7)\n",
    "            \n",
    "            y_lower = y_upper + 10\n",
    "        \n",
    "        ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", linewidth=2,label=f'Average ({silhouette_avg:.4f})')\n",
    "        ax.set_xlabel(\"Silhouette Coefficient\", fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel(\"Cluster\", fontsize=11, fontweight='bold')\n",
    "        ax.set_title(f'Silhouette Plot (K={optimal_k})', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylim([0, len(self.X) + (optimal_k + 1) * 10])\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.2, axis='x')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/03_silhouette_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\" Saved: results/03_silhouette_analysis.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26e69ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Dataset/Benign_Dump.pcap (Label: Benign)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Reading packets: 86000it [00:44, 1942.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Extracted 38444 flows\n",
      "   Aggregating benign flow features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Aggregating features: 100%|██████████| 38444/38444 [00:00<00:00, 43572.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Dataset/steganography_dataset_20251016_233034.pcap (Label: Steganography)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Reading packets: 92067it [01:17, 1195.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Extracted 81985 flows\n",
      "   Aggregating stego flow features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Aggregating features: 100%|██████████| 81985/81985 [00:01<00:00, 52973.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined dataset shape: (1673, 65)\n",
      "  - Samples: 1,673\n",
      "  - Features: 65 (13 dims × 5 stats)\n",
      "\n",
      "Class Distribution:\n",
      "   Benign                  611 ( 36.5%)\n",
      "   Steganography         1,062 ( 63.5%)\n",
      "\n",
      "Normalizing features...\n",
      "Features normalized\n",
      "\n",
      "Testing K values from 2 to 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Evaluating: 100%|██████████| 9/9 [00:01<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  - Optimal K (Silhouette): 2\n",
      "  - Best Silhouette Score: 0.6887\n",
      "\n",
      " Saved: results/01_elbow_analysis.png\n",
      "\n",
      "Clustering with K=2...\n",
      "Clustering completed\n",
      "\n",
      "Cluster Distribution:\n",
      "   Cluster 0:  1,492 ( 89.2%)\n",
      "   Cluster 1:    181 ( 10.8%)\n",
      "\n",
      "Cluster Purity Analysis:\n",
      "   Cluster 0:  71.2% Stego,  28.8% Benign [MIXED]\n",
      "   Cluster 1:   0.0% Stego, 100.0% Benign [PURE BENIGN]\n",
      "\n",
      "Applying PCA...\n",
      "✓ Explained variance: 48.04%\n",
      "  - PC1: 35.03%\n",
      "  - PC2: 13.01%\n",
      "\n",
      "======================================================================\n",
      " t-SNE DIMENSIONALITY REDUCTION\n",
      "======================================================================\n",
      "\n",
      "Applying t-SNE (may take a moment)...\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1673 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1673 samples in 0.093s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1673\n",
      "[t-SNE] Computed conditional probabilities for sample 1673 / 1673\n",
      "[t-SNE] Mean sigma: 0.063075\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 57.832058\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.439305\n",
      "t-SNE completed\n",
      "\n",
      "======================================================================\n",
      " GENERATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "✓ Saved: results/02_pca_clusters.png\n",
      " Saved: results/02_tsne_clusters.png\n",
      " Saved: results/03_silhouette_analysis.png\n",
      "\n",
      "Results saved in ./results/\n",
      "   - 01_elbow_analysis.png\n",
      "   - 02_pca_clusters.png\n",
      "   - 02_tsne_clusters.png\n",
      "   - 03_silhouette_analysis.png\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main pipeline\"\"\"\n",
    "    benign_pcap = \"Dataset/Benign_Dump.pcap\"\n",
    "    stego_pcap = \"Dataset/steganography_dataset_20251016_233034.pcap\"\n",
    "    \n",
    "    if not os.path.exists(benign_pcap) or not os.path.exists(stego_pcap):\n",
    "        print(\"PCAP files not found!\")\n",
    "        return\n",
    "    \n",
    "    # Initialize\n",
    "    clustering = UnsupervisedClusteringAnalysis()\n",
    "    \n",
    "    # Load features from PCAPs\n",
    "    clustering.load_features_from_pcaps(benign_pcap, stego_pcap,max_flows_per_class=500, sequence_length=50)\n",
    "    \n",
    "    # Find optimal K\n",
    "    optimal_k = clustering.determine_optimal_k(k_range=range(2, 11))\n",
    "    \n",
    "    # Perform clustering\n",
    "    clustering.perform_clustering(optimal_k)\n",
    "    \n",
    "    # Dimensionality reduction\n",
    "    X_pca = clustering.reduce_dimensions_pca()\n",
    "    X_tsne = clustering.reduce_dimensions_tsne()\n",
    "    \n",
    "    # Plot visualizations\n",
    "    clustering.plot_visualizations(X_pca, X_tsne, optimal_k)\n",
    "    \n",
    "    print(\"\\nResults saved in ./results/\")\n",
    "    print(\"   - 01_elbow_analysis.png\")\n",
    "    print(\"   - 02_pca_clusters.png\")\n",
    "    print(\"   - 02_tsne_clusters.png\")\n",
    "    print(\"   - 03_silhouette_analysis.png\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
